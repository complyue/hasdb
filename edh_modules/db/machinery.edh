{#
 # Machinery to build the exoskeleton for add-on persistence to
 # entity/relationship business objects.
 #}

import (

  # re-export these
  Vector, 
  className, 

  # don't re-export these
  Array as _Array
  newBo as _newBo, 
  streamToDisk as _streamToDisk, 
  streamFromDisk as _streamFromDisk, 

  **_  # consume (drop) extra artifacts exported there, don't fail
) 'db/RT'


import (

  # extend the host classes as to be duck-typed collection classes
  BoSet as _BoSet,
  BoIndex as _BoIndex,
  BuIndex as _BuIndex,

  **_  # consume (drop) extra artifacts exported there, don't fail
) 'db/Storage/InMem'

# duck-typed KinColection, concrete implementations:
#  * BoSet    - unordered set
#  * BoIndex  - sorted by index key attributes, non-unique
#  * BuIndex  - sorted by index key attributes, unique
class KinCollection {

  # to enumerate all relatipnship business objects one by one
  generator all() error('abstract method')

  # to enumerate all relationship business objects group by group,
  # together with the index key attributes, in order of the index.
  generator groups() error('abstract method')

  # to enumerate all relationship business objects one by one,
  # together with the index key attributes, in order of the index.
  generator range() error('abstract method')

}

class BoSet {
  # no ctor arg
  extends _BoSet()

  # to satisfy the duck typing criteria
  generator groups() {
    for bo from super.all() do yield pkargs( (), (bo,) )
  }
  generator range() {
    for bo from super.all() do yield pkargs( (), bo )
  }
}

class BoIndex {
  # pass verbatim ctor args to the super host class
  method __init__(***apk) extends _BoIndex(***apk)

  # to satisfy the duck typing criteria
  generator all() {
    for ( k, g ) from super.groups() do for bo from g do {
      yield bo
    }
  }
  generator range() {
    for ( k, g ) from super.groups() do for bo from g do {
      yield pkargs( k, bo )
    }
  }
}

class BuIndex {
  # pass verbatim ctor args to the super host class
  method __init__(***apk) extends _BuIndex(***apk)

  # to satisfy the duck typing criteria
  generator all() {
    for ( k, bo ) from super.groups() do {
      yield bo
    }
  }
  generator groups() {
    for ( k, bo ) from super.groups() do {
      yield pkargs( k, (bo,) )
    }
  }
}

# this tells persistent attributes from transient ones
method hasReConRepr( attrVal ) case attrVal of {
  {{ _Array: _ }} -> true;
  {{ Vector: _ }} -> true;
  ;| type( attrVal ) ?<= [
    # types reconstructable from its textual representation
    nil,  # absent attribute
    BoolType, DecimalType, StringType,  # literal values
    # TODO validate deep content in a container are reconstructable from repr
    PairType, TupleType, ListType, DictType,  # containers
    ArgsPackType,  # complexer container
  ] -> true
  false
}

method runDbApp(dataDir, dbApp) {

  # the persister will post the fd it opened as the latest data file
  # to this sink, it'll hold this fd open until it finalized a new data
  # file at the time the db is shutdown. the fd is passed to `db.init()`
  # so business objects from that file can be restored into RAM before
  # the db app is run.
  sinkBaseDFD = sink

  db = DataBack( dataDir, dbApp )

  # the producer procedure to be launched for db app
  producer launchApp( outlet ) {

    # to avoid the dreadful STM crash:
    #  `thread blocked indefinitely in an STM transaction`
    # in case some error occurred before cleanly shutdown,
    # just mark eos of persistOutlet to let go `db._streamToDisk()`,
    # and we will be able to see details of the error spat out.
    defer { outlet <- nil }

    debug&>{go{
      for pr from outlet do {  # dump persistence payload
        console.debug <| 'persistOutlet REC\n' ++ pr
      }
      console.debug <| 'persistOutlet EOS'
    }}

    # read the most recent event from the sink, it must have been there already,
    # as `_streamToDisk()` won't subscribe to the persist outlet (only after 
    # which this producer proc will run) until it resolved the latest data file.
    db.init( outlet, mre( sinkBaseDFD ) )

  }

  # serialize the stream of sunk Edh values to the specified data folder
  db._streamToDisk ( launchApp(), dataDir, sinkBaseDFD )

}

class DataBackLifecycle {

  # make these host methods available from db's super, and called against the db
  # instance, so the host procs can obtain the db instance via `that` reference
  _streamToDisk = _streamToDisk
  _streamFromDisk = _streamFromDisk

  # this is the entry point of a db app, the concrete app can selectively
  # override some of the methods invoked here.
  method init( 
    persistOutlet as that.persistOutlet,  # put it to db instance
    baseDFD ) {
    # note `that` reference won't invoke magics, just does vanilla
    # attribute resolution and do the call against the result.

    # a db app needs this chance to prepare itself for history replay
    that.bootstrap()

    producer restoreData( outlet ) {
      that._streamFromDisk( outlet, baseDFD )
    }
    that._replayHistory( restoreData() )

    that._dumpBaseData()

    # TODO take this chance to physically discard older files in the data 
    #      folder, as a means of automatic compacting of backing storage.

    that.run()

    that.shutdown()
  }

  # provide default impl. of the lifecycle methods so the db app does not
  # have to impl. all of them.

  method bootstrap() pass
  
  method run() pass

  method shutdown() {
    that.persistOutlet <- nil
  }

}

class DataBack {
  extends( DataBackLifecycle() )

  method __init__ (
    dataDir as this.dataDir,
    dbApp,
  ) {
    # have the app as 1st super, so it can override DataBackLifecycle methods
    # invoked from this db instance
    extends( dbApp )
  }

  method Array (***apk) {
    _Array( this.dataDir, ***apk )
  }

  # all global indices created. a hierarchy of dicts by class then by key attr,
  # to a list of index entries for indices having the key attr involved.
  _indices = {}

  # this method is normally called as the right-hand-expr of an assignment
  # (to an attribute of the db app), so it tends to run within a tx already,
  # we mark it with `ai` for extra certain.
  method createIndex( idxAttr, boClass, indexSpec, unique=false ) ai {
    idx = if unique
      then BuIndex( indexSpec, name=''++idxAttr++'@'++boClass )
      else BoIndex( indexSpec, name=''++idxAttr++'@'++boClass )
    bocIndices = this._indices[boClass] |>    (
                 this._indices[boClass] = {} )
    for keyAttr from idx.keys do idx => (
      bocIndices[ keyAttr ] |>   (
      bocIndices[ keyAttr ] = [] )
    )
    this$idxAttr = idx
    return nil
  }

  # the last entity identifier allocated
  # todo change to uuid for security reasons in production, instead of the
  #      trivial natural numbers as for now
  _last_eid = 0

  # reference all live business objects by eid, with each business 
  # class having a separate dict in `_extents`
  _extents = {}

  # the version number that all live objects have been dumped
  _dump_version = 0

  method superBack() {
    SuperBack( db=this, eid=this._last_eid+=1, )
  }

  # settle a new business object
  # in a tx process all attributes atm
  method _settle_obj( bo, sb ) ai {
    boClass = constructor(bo)
    bocIndices = this._indices[ boClass ] |> None
    touchedIndices = {}  # collect touched global indices by attr
    persistAttrs = []
    for (attrKey, attrVal) from sb._boScope.attrs() do case attrVal of {
      # referencing another business object, settle the relationship
      {{ SuperBack: sbRef }} ->  {
        this._settle_rel( bo, sb, attrKey, attrVal, sbRef )

        # encounter the new relationship
        ;( attrKey, className(attrVal), sbRef.eid ) => persistAttrs
      }
      # handle trivially representable values, including `nil`
      ;| hasReConRepr(attrVal) -> {
        # encounter touched index by this attr
        case bocIndices &> bocIndices[ attrKey ] |> nil of { bois } -> {
          for boi from bois do
            touchedIndices[ boi ] = true
        }

        # encounter the new attribute value
        ;( attrKey, attrVal ) => persistAttrs
      }
      # not to persist, treating as a transient attribute
      {#
      console.debug<| 'attribute of type ' ++ type(attrVal)
        ++ ' treated as transient attribute ' ++ attrKey 
        ++ ' for business object ' ++ sb.eid
        ++ ' of class defined at ' ++ sb._boScope.lexiLoc()
      #}
    }

    # put into global extent
    case this._extents[boClass] of {
      nil -> this._extents[boClass] = {
        sb.eid: bo
      }
      { boExtent } -> {
        boExtent[sb.eid] = bo
      }
    }

    # index into all touched global indices
    for (boi, _) from touchedIndices do boi.(<-)(bo)

    # persist all attributes of the new business object
    this.persistOutlet <- (className(bo), sb.eid, persistAttrs)
  }

  # settle an attribute update
  method _settle_attr( bo, sb, attrKey, attrVal ) case attrVal of {
    # referencing another business object, settle the relationship
    {{ SuperBack: sbRef }} ->  {
      this._settle_rel( bo, sb, attrKey, attrVal, sbRef )

      # persist the new relationship
      this.persistOutlet <- (className(bo), sb.eid, [
        (attrKey, className(attrVal), sbRef.eid)
      ])
    }

    # handle trivially representable values, including `nil`
    ;| hasReConRepr(attrVal) -> {
      # re-index to the global index if any touched
      case this._indices[ constructor(bo) ] of { bocIndices } -> {
        case bocIndices[ attrKey ] of { bois } -> {
          for boi from bois do
            boi.(<-)(bo)
        }
      }

      # persist the new attribute value
      this.persistOutlet <- (className(bo), sb.eid, [
        (attrKey, attrVal)
      ])
    }

    # not to persist, treating as a transient attribute
    {#
    console.debug<| 'attribute of type ' ++ type(attrVal)
      ++ ' treated as transient attribute ' ++ attrKey 
      ++ ' for business object ' ++ sb.eid
      ++ ' of class defined at ' ++ sb._boScope.lexiLoc()
    #}
  }

  # settle a new relationship
  method _settle_rel( boRel, sbRel, refAttr, bo, sb ) {
    # update reverse reference on the referee sb's kin index/set if any
    case sb._kins[ constructor(boRel):(''++refAttr) ] of { kin } -> {
      kin.(<-)(boRel)
    }
  }

  # cleanup an old relationship
  method _cleanup_rel( boRel, sbRel, refAttr, boOld, sbOld ) {
    # throw away reverse reference on the referee sb's kin index/set if any
    case sbOld._kins[ constructor(boRel):(''++refAttr) ] of { kin } -> {
      kin.(^*)(boRel)
    }
  }

  # dump all live business objects to persistent outlet, this has all live
  # objects atm to be recorded by the current backing data file, especially
  # without objects had been alive but deleted during replay of history.
  method _dumpBaseData() {
    # mark a new dump by increasing the version
    this._dump_version += 1

    method _dumpBo( bo, sb ) {
      if sb?_dumped_version == this._dump_version then {
        return nil  # this bo already dumped to version
      }

console.debug<| 'persist dump '++className(bo)++' # '++sb.eid

      persistAttrs = []
      for (attrKey, attrVal) from sb._boScope.attrs() do case attrVal of {
        # referencing another business object
        {{ SuperBack: sbRef }} ->  {
          # dump the referee now to ensure it'll be restored before this bo
          # being restored, in future replays of history
          _dumpBo( attrVal, sbRef )
          # record this ref attr
          ;( attrKey, className(attrVal), sbRef.eid ) => persistAttrs
        }
        # handle trivially representable values, including `nil`
        ;| hasReConRepr(attrVal) -> {
          # encounter the new attribute value
          ;( attrKey, attrVal ) => persistAttrs
        }
        # not to persist, treating as a transient attribute
        {#
        console.debug<| 'attribute of type ' ++ type(attrVal)
          ++ ' treated as transient attribute ' ++ attrKey 
          ++ ' for business object ' ++ sb.eid
          ++ ' of class defined at ' ++ sb._boScope.lexiLoc()
        #}
      }

      # persist all attributes of this business object
      this.persistOutlet <- (className(bo), sb.eid, persistAttrs)
      # mark it dumped to version
      sb._dumped_version = this._dump_version
    }

    # dump all live objects in extent
    for (boClass, boExtent) from this._extents do {
      for (eid, bo) from boExtent do case bo of {{ SuperBack: sb }} -> {
        #if eid != sb.eid then
        #  error( 'bug: eid mismatch ' ++ eid ++ ' vs ' ++ sb.eid )
        _dumpBo( bo, sb )
      }
    }
  }

  method _cleanout_obj ( bo, sb, persist=true ) {
    boClass = constructor(bo)
    bocIndices = this._indices[ boClass ] |> None
    touchedIndices = {}  # collect touched global indices by attr

    for (attrKey, attrVal) from sb._boScope.attrs() do case attrVal of {
      # referencing another business object, settle the relationship
      {{ SuperBack: sbRef }} ->  {
        this._cleanup_rel( bo, sb, attrKey, attrVal, sbRef )
      }
      # handle trivially representable values, including `nil`
      ;| hasReConRepr(attrVal) -> {
        # encounter touched index by sb attr
        case bocIndices &> bocIndices[ attrKey ] |> nil of { bois } -> 
         for boi from bois do {
            touchedIndices[ boi ] = true
        }
      }
    }

    for (kinKey, boKins) from sb._kins do {
      for boKin from boKins.all() do case boKin of {{ SuperBack: sbKin }} -> {
        this._cleanout_obj( boKin, sbKin, persist=persist )
      }
    }

    # remove from global extent
    case this._extents[boClass] of { bocExtent } -> {
      bocExtent[sb.eid] = nil
    }

    # throw away from all touched global indices
    for (boi, _) from touchedIndices do boi.(^*)(bo)

    if persist then {
      # persist the log
      this.persistOutlet <- (className(bo), sb.eid, ())
    }

    return nil
  }

  # restore all business objects into RAM from the backing storage, i.e
  # lastest finalized data file. all persistent CUD operations are replayed.
  method _replayHistory( intakeSink ) {
    for persistRecord from intakeSink do case persistRecord of {
      {( boClassName, eid, attrChgs )} -> {
        # db has the mounted DbApp as a super, resolving business classes
        # by name from there
        boClass = super?$boClassName
        if ClassType != type(boClass) then error (
          'Business class ' ++ boClassName ++ ' not available!'
        )

        # admit historical largest eid, will not be needed in uuid schema
        ai if eid > this._last_eid then
          this._last_eid = eid

        bocExtent = this._extents[boClass] |>    (
                    this._extents[boClass] = {} )

        case bo = bocExtent[eid] of {
          nil -> {
            # this bo not created yet, do non-standard construction of the
            # business object
            sb = SuperBack( this, eid )
            bo = _newBo( boClass, sb )

            bocExtent[eid] = bo
          }
          {{ SuperBack: sb }} -> {
            pass  # already created, proceed to apply attr updates
          }
          error( 'bug: no SuperBack on existing bo' )
        }

        bocIndices = this._indices[ boClass ] |> None
        touchedIndices = {}  # collect touched global indices by attr
        if null(attrChgs) then {  # deletion
            this._cleanout_obj( bo, sb, persist=false )
            continue
        }
        newReferees = []
        for attrChg from attrChgs do case attrChg of {
          # change of relationship
          {( attrKey, refClassName, eidRef )} -> {
            refClass = super?$refClassName
            if ClassType != type(refClass) then error (
              'Business class ' ++ refClassName ++ ' not available!'
            )
            case (refExtent = this._extents[refClass]) &> refExtent[eidRef] of {
              nil -> error( 'The business object ' ++ refClassName ++ '#' ++ eidRef 
                  ++ ' lost, referenced via ' ++ attrKey ++ ' by ' ++ boClassName 
                  ++ '#' ++ eid )
              { boRef } -> { pass }
            }

            # cleanup the old relationship
            case attrValOld = sb._boScope.get(attrKey) of {{ SuperBack: sbRefOld }} ->
              this._cleanup_rel( bo, sb, attrKey, attrValOld, sbRefOld)

            # remember this new referee to connect
            case boRef of {{ SuperBack: sbRef }} -> {
              pkargs( attrKey, boRef, sbRef ) => newReferees
            }
          }

          # change of trivial attribute
          {( attrKey, attrVal )} -> {
            # encounter touched index by this attr
            case bocIndices &> bocIndices[ attrKey ] |> nil of { bois } -> {
              for boi from bois do
                touchedIndices[ boi ] = true
            }

            # update attr without magic
            sb._boScope.put(attrKey: attrVal)
          }

          error( 'bug: unsupported persistent attr chg pattern', 
            type=type(attrChg), value=attrChg )
        }
        # settle the relationship only after all attr updates are applied, or
        # the kin indices at referees might capture wrong index keys
        for ( attrKey, boRef, sbRef ) from newReferees do {
          # update ref attr of this relationship without magic
          sb._boScope.put(attrKey: boRef)
          # settle the relationship
          this._settle_rel( bo, sb, attrKey, boRef, sbRef )
        }
        # re-index into all touched global indices
        for (boi, _) from touchedIndices do boi.(<-)(bo)
      }

      error( 'bug: unsupported persistent record pattern' 
        type=type(persistRecord), value=persistRecord )
    }
  }

}

class SuperBack {

  method __init__ (
    db as this.db, eid as this.eid,
  ) pass
  
  # informed reverse references, to referencers of `that` business object,
  # keyed by a pair of <rel-class>:<ref-attr>, then by the key attrs.
  _kins = {}

  # create an index for sorted kins, that automatically maintained by the data
  # back.
  #
  # a kin to a business object - the referee - (being either an entity or a
  # relationship), is another relationship object - the referer - which (through
  # a specific attribute) referencing the referee.
  #
  # DataBack automatically maintains a reverse reference from the referee to
  # the referer within an BoIndex object created by `createKinIndex()` or
  # BoSet object created by `createKinSet()`, resides in the referee's SuperBack
  # super object, available as a super attribute there from the referee object.
  method createKinIndex ( kinAttr, relClass, relAttr, indexSpec, unique=false ) {
    idxName = kinAttr++'@'++className(that)++'<-'++relClass++'.'++relAttr
    idx = if unique
      then BuIndex( indexSpec, name=idxName )
      else BoIndex( indexSpec, name=idxName )
    # chain the 2 assignments into single transaction
    this._kins[ relClass:(''++relAttr) ] = (
      # will be available from `that` as super attr
      this$kinAttr = idx
    )
    return nil
  }

  # create a set for unordered kins, that automatically maintained by the data
  # back.
  #
  # a kin to a business object - the referee - (being either an entity or a
  # relationship), is another relationship object - the referer - which (through
  # a specific attribute) referencing the referee.
  #
  # DataBack automatically maintains a reverse reference from the referee to
  # the referer within an BoIndex object created by `createKinIndex()` or
  # BoSet object created by `createKinSet()`, resides in the referee's SuperBack
  # super object, available as a super attribute there from the referee object.
  method createKinSet ( kinAttr, relClass, relAttr ) {
    ks = BoSet()
    # chain the 2 assignments into single transaction
    this._kins[ relClass:(''++relAttr) ] = (
      # will be available from `that` as super attr
      this$kinAttr = ks
    )
    return nil
  }

  # `extends db.superBack()` from a business object's __init__() triggers
  # this magic method, such a statement carries *persistent object creation*
  # semantic regarding the target `db` being the persistence backer.
  method (<-^) (boScope) {
    this?_boScope &> error (
      'bug: more than 1 business objects per SuperBack instance'
    )
    this._boScope = boScope

    case that?__db_init__ of { _ } -> that.__db_init__()

    # settle new object
    this.db._settle_obj( that, this )
  }

  # ( <-@) handles `this.xxx = yyy` from a business child (referred to by `that`)
  # (*<-@) handles `obj.xxx = yyy` for `obj` being a business child (referred to by `that`)

  method (*<-@) (attrKey, attrVal) {
    case that?$attrKey of { attrValOld } -> {
      if attrValOld == attrVal then {
        return attrVal  # no value change, nop
      }

      # cleanup the old relationship
      case attrValOld of {{ SuperBack: sbRefOld }} ->
        this.db._cleanup_rel( that, this, attrKey, attrValOld, sbRefOld)
    }

    # apply the attribute update
    that$attrKey = attrVal

    # settle new attribute
    this.db._settle_attr( that, this, attrKey, attrVal )

    attrVal  # keep the assignment result eval to target value as in normal cases
  }

  # use same method impl. for (<-@) and (*<-@), treating internal/external attr
  # updates the same
  this.(<-@) = (*<-@)

  # delete this business object in persistence respect
  method delete() this.db._cleanout_obj( that, this )

}

