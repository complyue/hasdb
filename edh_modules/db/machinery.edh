{#
 # Machinery to build the exoskeleton for add-on persistence to
 # entity/relationship business objects.
 #}

# bring default dtype identifiers into here
import * 'dim/dtypes'

import (
  DbArray,
  newBo,
  streamToDisk,
  streamFromDisk,
  **_, # consume (drop) extra artifacts exported there, don't fail
) 'db/RT'

import (
  # extend the host classes as to be duck-typed collection classes
  BoSet as _BoSet,
  BoIndex as _BoIndex,
  BuIndex as _BuIndex,
  **_, # consume (drop) extra artifacts exported there, don't fail
) 'db/Storage/InMem'


# duck-typed KinColection interface, abstracting concrete implementations:
#  * BoSet    - unordered set
#  * BoIndex  - sorted by index key attributes, non-unique
#  * BuIndex  - sorted by index key attributes, unique
namespace KinCollection () {

  # to enumerate all relatipnship business objects one by one
  generator all() error( 'abstract method' )

  # to enumerate all relationship business objects group by group,
  # together with the index key attributes, in order of the index.
  generator groups() error( 'abstract method' )

  # to enumerate all relationship business objects one by one,
  # together with the index key attributes, in order of the index.
  generator range() error( 'abstract method' )

}

namespace BoSet'Ducking () {
  # to satisfy the duck typing criteria
  generator groups() {
    for bo from that.all() do yield ( (), ( bo, ) )
  }
  generator range() {
    for bo from that.all() do yield ( (), bo )
  }
}
export class BoSet {
  extends BoSet'Ducking
  # no ctor arg
  extends _BoSet()
}


namespace BoIndex'Ducking () {
  # to satisfy the duck typing criteria
  generator all() {
    for ( k, g ) from that.groups() do for bo from g do {
      yield bo
    }
  }
  generator range() {
    for ( k, g ) from that.groups() do for bo from g do {
      yield ( k, bo )
    }
  }
}
export class BoIndex {
  extends BoIndex'Ducking
  # pass verbatim ctor args to the super host class
  method __init__(*** apk ) {
    extends _BoIndex(*** apk )
  }
}


namespace BuIndex'Ducking () {
  # to satisfy the duck typing criteria
  generator all() {
    for ( k, bo ) from that.range() do {
      yield bo
    }
  }
  generator groups() {
    for ( k, bo ) from that.range() do {
      yield ( k, ( bo, ) )
    }
  }
}
export class BuIndex {
  extends BuIndex'Ducking
  # pass verbatim ctor args to the super host class
  method __init__(*** apk ) {
    extends _BuIndex(*** apk )
  }
}


export method className( o ) case constructor( o ) of { cls } -> cls.name

# this tells persistent attributes from transient ones
method hasReConRepr( attrVal ) case attrVal of {
  None -> true
  { term := val } -> hasReConRepr( val )

  # non-transactional containers
  { { Vector: _ } } -> true
  { { DbArray: _ } } -> true

  ; | type( attrVal ) ?<= [
    # types reconstructable from its textual representation
    BoolType, DecimalType, StringType, # literal values
    # TODO validate that, the deep content in these containers are
    # reconstructable from repr
    PairType, ArgsPackType, # immutable containers
    ListType, DictType, # mutable containers
  ] -> true

  false
}

export method runDbApp( dataDir, dbApp ) {

  # bring fallback supporting effects of dtypes into here
  effect import * 'dim/effects'

  # the persister will post the fd it opened as the latest data file
  # to this sink, it'll hold this fd open until it finalized a new data
  # file at the time the db is shutdown. the fd is passed to `db.init()`
  # so business objects from that file can be restored into RAM before
  # the db app is run.
  sinkBaseDFD = sink

  case DataBack( dataDir, dbApp ) of { db } -> { pass }

  # the producer procedure to be launched for db app
  producer launchApp( outlet ) {

    # to avoid the dreadful STM crash:
    #  `thread blocked indefinitely in an STM transaction`
    # in case some error occurred before cleanly shutdown,
    # just mark eos of persistOutlet to let go `db._streamToDisk()`,
    # and we will be able to see details of the error spat out.
    defer { outlet <- nil }

    {#
    debug&>{go{
    for pr from outlet do {  # dump persistence payload
    console.debug <| 'persistOutlet REC\n' ++ pr
    }
    console.debug <| 'persistOutlet EOS'
    }}
     #}

    # read the most recent event from the sink, it must have been there already,
    # as `_streamToDisk()` won't subscribe to the persist outlet (only after
    # which this producer proc will run) until it resolved the latest data file.
    db.init( outlet, mre( sinkBaseDFD ) )

  }

  # serialize the stream of sunk Edh values to the specified data folder
  db._streamToDisk ( launchApp(), dataDir, sinkBaseDFD )

}

class DataBackLifecycle {

  # make these host methods available from db's super, and called against the db
  # instance, so the host procs can obtain the db instance via `that` reference
  _streamToDisk = streamToDisk
  _streamFromDisk = streamFromDisk

  # this is the entry point of a db app, the concrete app can selectively
  # override some of the methods invoked here.
  method init(
    persistOutlet as that.persistOutlet, # put it to db instance
    baseDFD,
  ) {
    # note `that` reference won't invoke magics, just does vanilla
    # attribute resolution and do the call against the result.

    # a db app needs this chance to prepare itself for history replay
    that.bootstrap()

    producer restoreData( outlet ) {
      db = that # persisted repr may reference `db` upon being restored
      that._streamFromDisk( outlet, baseDFD )
    }
    that._replayHistory( restoreData() )

    that._dumpBaseData()

    # TODO take this chance to physically discard older files in the data
    #      folder, as a means of automatic compacting of backing storage.

    that.run()

    that.shutdown()
  }

  # provide default impl. of the lifecycle methods so the db app does not
  # have to impl. all of them.

  method bootstrap() pass

  method run() pass

  method shutdown() {
    that.persistOutlet <- nil
  }

}

export class DataBack {
  extends( DataBackLifecycle() )

  # this is to be set upon `runDbApp()`, which calls `db.init()`
  persistOutlet ?= None

  method __init__ (
    dataDir as this.dataDir,
    dbApp,
  ) {
    # have the app as 1st super, so it can override DataBackLifecycle methods
    # invoked from this db instance
    extends( dbApp )
  }

  method Array (*** apk ) {
    effect _loadDbArrays = false
    DbArray( this.dataDir, *** apk )
  }

  # all global indices created. a hierarchy of dicts by class then by key attr,
  # to a list of index entries for indices having the key attr involved.
  _indices = {}

  # this method is normally called as the right-hand-expr of an assignment
  # (to an attribute of the db app), so it tends to run within a tx already,
  # we mark it with `ai` for extra certain.
  method createIndex( idxAttr, boClass, indexSpec, unique=false ) ai {
    idx = if unique
    then BuIndex( indexSpec )
    else BoIndex( indexSpec )
    bocIndices = this._indices[ boClass ] |> (
      this._indices[ boClass ] = {} )
    for keyAttr from idx.keys() do idx => (
      bocIndices[ keyAttr ] |> (
        bocIndices[ keyAttr ] = [] )
    )
    this@idxAttr = idx
    return nil
  }

  # the last entity identifier allocated
  # todo change to uuid for security reasons in production, instead of the
  #      trivial natural numbers as for now
  _last_eid = 0

  # reference all live business objects by eid, with each business
  # class having a separate dict in `_extents`
  _extents = {}

  # the version number that all live objects have been dumped,
  # negative number means never dumped, thus still replaying history
  _dump_version = -1

  method superBack() {
    SuperBack( db=this, eid=this._last_eid+=1, )
  }

  # settle a new business object
  # in a tx process all attributes atm
  method _settle_obj( bo, sb ) ai {
    boClass = constructor( bo )
    bocIndices = this._indices[ boClass ] |> None
    touchedIndices = {} # collect touched global indices by attr
    persistAttrs = []
    for ( attrKey, attrVal ) from sb._boScope.attrs()
    do | type( attrKey ) is StringType # treat all symbolic attrs as transient
    -> case attrVal of {
      # referencing another business object, settle the relationship
      { { SuperBack: sbRef } } -> {
        this._settle_rel( bo, sb, attrKey, attrVal, sbRef )

        # encounter the new relationship
        ; ( attrKey, className( attrVal ), sbRef.eid ) => persistAttrs
      }
      # handle trivially representable values, including `nil`
      ; | hasReConRepr( attrVal ) -> {
        # encounter touched index by this attr
        case bocIndices &> bocIndices[ attrKey ] |> nil of { bois } -> {
          for boi from bois do
          touchedIndices[ boi ] = true
        }

        # encounter the new attribute value
        ; ( attrKey, attrVal ) => persistAttrs
      }
      # not to persist, treating as a transient attribute
      {#
      console.debug<| 'attribute of type ' ++ type(attrVal)
      ++ ' treated as transient attribute ' ++ attrKey
      ++ ' for business object ' ++ sb.eid
      ++ ' of class defined at ' ++ sb._boScope.lexiLoc()
       #}
    }

    # put into global extent
    case this._extents[ boClass ] of {
      { boExtent } -> {
        boExtent[ sb.eid ] = bo
      }
      this._extents[ boClass ] = {
        sb.eid: bo
      }
    }

    # index into all touched global indices
    for ( boi, _ ) from touchedIndices do boi <- bo

    if this._dump_version >= 0 then {
      # persist all attributes of the new business object
      this.persistOutlet <- ( className( bo ), sb.eid, persistAttrs )
    }
  }

  # settle an attribute update
  method _settle_attr( bo, sb, attrKey, attrVal ) case attrVal of {
    # referencing another business object, settle the relationship
    { { SuperBack: sbRef } } -> {
      this._settle_rel( bo, sb, attrKey, attrVal, sbRef )
    }

    # handle trivially representable values, including `nil`
    ; | hasReConRepr( attrVal ) -> {
      # re-index to the global index if any touched
      case this._indices[ constructor( bo ) ] of { bocIndices } -> {
        case bocIndices[ attrKey ] of { bois } -> {
          for boi from bois do boi <- bo
        }
      }

      if this._dump_version >= 0 then {
        # persist the new attribute value
        this.persistOutlet <- ( className( bo ), sb.eid, [
            ( attrKey, attrVal )
        ] )
      }
    }

    # not to persist, treating as a transient attribute
    {#
    console.debug<| 'attribute of type ' ++ type(attrVal)
    ++ ' treated as transient attribute ' ++ attrKey
    ++ ' for business object ' ++ sb.eid
    ++ ' of class defined at ' ++ sb._boScope.lexiLoc()
     #}
  }

  # settle a new relationship
  method _settle_rel( boRel, sbRel, refAttr, bo, sb ) {

    # ; -1<| Exception( 'settle rel ' ++ className( boRel ) ++ ' # ' ++ sbRel.eid )
    # shellHere() # not possible, here is in tx

    # update reverse reference on the referee sb's kin index/set if any
    case sb._kins[ constructor( boRel ) : ( '' ++ refAttr ) ] of { kin } -> {


      kin <- boRel
    }
    if this._dump_version >= 0 then {
      # persist the new relationship
      this.persistOutlet <- ( className( boRel ), sbRel.eid, [
          ( refAttr, className( bo ), sb.eid )
      ] )
    }
  }

  # cleanup an old relationship
  method _cleanup_rel( boRel, sbRel, refAttr, boOld, sbOld ) {
    # throw away reverse reference on the referee sb's kin index/set if any
    case sbOld._kins[ constructor( boRel ) : ( '' ++ refAttr ) ] of { kin } -> {
      kin ^* boRel
    }
  }

  # dump all live business objects to persistent outlet, this has all live
  # objects atm to be recorded by the current backing data file, especially
  # without objects had been alive but deleted during replay of history.
  method _dumpBaseData() {
    # mark a new dump by increasing the version
    this._dump_version += 1

    console.debug<| 'starting dump version ' ++ this._dump_version

    method _dumpBo( bo, sb ) {
      if sb?_dumped_version is this._dump_version then {
        return nil # this bo already dumped to version
      }

      console.debug<| 'persist dump ' ++ className( bo ) ++ ' # ' ++ sb.eid

      persistAttrs = []
      for ( attrKey, attrVal ) from sb._boScope.attrs() do case attrVal of {
        # referencing another business object
        { { SuperBack: sbRef } } -> {
          # dump the referee now to ensure it'll be restored before this bo
          # being restored, in future replays of history
          _dumpBo( attrVal, sbRef )
          # record this ref attr
          ; ( attrKey, className( attrVal ), sbRef.eid ) => persistAttrs
        }
        # handle trivially representable values, including `nil`
        ; | hasReConRepr( attrVal ) -> {
          # encounter the new attribute value
          ; ( attrKey, attrVal ) => persistAttrs
        }
        # not to persist, treating as a transient attribute
        {#
        console.debug<| 'attribute of type ' ++ type(attrVal)
        ++ ' treated as transient attribute ' ++ attrKey
        ++ ' for business object ' ++ sb.eid
        ++ ' of class defined at ' ++ sb._boScope.lexiLoc()
         #}
      }

      # persist all attributes of this business object
      this.persistOutlet <- ( className( bo ), sb.eid, persistAttrs )
      # mark it dumped to version
      sb._dumped_version = this._dump_version
    }

    # dump all live objects in extent
    for ( boClass, boExtent ) from this._extents do {
      for ( eid, bo ) from boExtent do case bo of { { SuperBack: sb } } -> {
        #if eid != sb.eid then
        #  error( 'bug: eid mismatch ' ++ eid ++ ' vs ' ++ sb.eid )
        _dumpBo( bo, sb )
      }
    }

    # baseline the base data from history replay
    this.syncData( '<baseline>' )
  }

  method _cleanout_obj ( bo, sb, persist=true ) {
    boClass = constructor( bo )
    bocIndices = this._indices[ boClass ] |> None
    touchedIndices = {} # collect touched global indices by attr

    for ( attrKey, attrVal ) from sb._boScope.attrs() do case attrVal of {
      # referencing another business object, settle the relationship
      { { SuperBack: sbRef } } -> {
        this._cleanup_rel( bo, sb, attrKey, attrVal, sbRef )
      }
      # handle trivially representable values, including `nil`
      ; | hasReConRepr( attrVal ) -> {
        # encounter touched index by sb attr
        case bocIndices &> bocIndices[ attrKey ] |> nil of { bois } ->
        for boi from bois do {
          touchedIndices[ boi ] = true
        }
      }
    }

    for ( kinKey, boKins ) from sb._kins do {
      for boKin from boKins.all() do case boKin of { { SuperBack: sbKin } } -> {
        this._cleanout_obj( boKin, sbKin, persist=persist )
      }
    }

    # remove from global extent
    case this._extents[ boClass ] of { bocExtent } -> {
      bocExtent[ sb.eid ] = nil
    }

    # throw away from all touched global indices
    for ( boi, _ ) from touchedIndices do boi ^* bo

    if persist then {
      # persist the log
      this.persistOutlet <- ( className( bo ), sb.eid, () )
    }

    return nil
  }

  # restore all business objects into RAM from the backing storage, i.e
  # lastest finalized data file. all persistent CUD operations are replayed.
  method _replayHistory( intakeSink ) {
    for (*** persistRecord ) from intakeSink do case persistRecord of {
      { ( boClassName, eid, attrChgs ) } -> {
        # db has the mounted DbApp as a super, resolving business classes
        # by name from there
        boClass = super?@boClassName
        if ClassType != type( boClass ) then error (
          'Business class ' ++ boClassName ++ ' not available!'
        )

        # admit historical largest eid, will not be needed in uuid schema
        ai if eid > this._last_eid then
        this._last_eid = eid

        bocExtent = this._extents[ boClass ] |> (
          this._extents[ boClass ] = {} )

        case bo = bocExtent[ eid ] of {
          nil -> {
            # this bo not created yet, do non-standard construction of the
            # business object
            sb = SuperBack( this, eid )
            bo = newBo( boClass, sb )

            bocExtent[ eid ] = bo
          }
          { { SuperBack: sb } } -> {
            pass # already created, proceed to apply attr updates
          }
          error( 'bug: no SuperBack on existing bo' )
        }

        bocIndices = this._indices[ boClass ] |> None
        touchedIndices = {} # collect touched global indices by attr
        if null( attrChgs ) then { # deletion
          this._cleanout_obj( bo, sb, persist=false )
          continue
        }
        newReferees = []
        for (*** attrChg ) from attrChgs do case attrChg of {
          # change of relationship
          { ( attrKey, refClassName, eidRef ) } -> {
            refClass = super?@refClassName
            if ClassType != type( refClass ) then error (
              'Business class ' ++ refClassName ++ ' not available!'
            )

            case ( this._extents[ refClass ] |> {} ) [ eidRef ] of {
              nil -> error( 'The business object ' ++ refClassName ++ '#' ++ eidRef
                ++ ' lost, referenced via ' ++ attrKey ++ ' by ' ++ boClassName
                ++ '#' ++ eid )
              { boRef } -> { pass }
            }

            # cleanup the old relationship
            case attrValOld = sb._boScope.get( attrKey ) of { { SuperBack: sbRefOld } } ->
            this._cleanup_rel( bo, sb, attrKey, attrValOld, sbRefOld )

            # remember this new referee to connect
            case boRef of { { SuperBack: sbRef } } -> {
              ( attrKey, boRef, sbRef ) => newReferees
            }
          }

          # change of trivial attribute
          { ( attrKey, attrVal ) } -> {
            # encounter touched index by this attr
            case bocIndices &> bocIndices[ attrKey ] |> nil of { bois } -> {
              for boi from bois do
              touchedIndices[ boi ] = true
            }

            # update attr without magic
            sb._boScope.put( attrKey: attrVal )
          }

          error( 'bug: unsupported persistent attr chg pattern',
            type=type( attrChg ), value=attrChg )
        }
        # settle the relationship only after all attr updates are applied, or
        # the kin indices at referees might capture wrong index keys
        for ( attrKey, boRef, sbRef ) from newReferees do {
          # update ref attr of this relationship without magic
          sb._boScope.put( attrKey: boRef )
          # settle the relationship
          this._settle_rel( bo, sb, attrKey, boRef, sbRef )
        }
        # re-index into all touched global indices
        for ( boi, _ ) from touchedIndices do boi <- bo
      }

      error( 'bug: unsupported persistent record pattern'
        type= type( persistRecord ), value=persistRecord )
    }
  }

  # issue and wait-done a system sync point
  method syncData( ssp = None ) {
    case type( ssp ) of {
      StringType -> { pass }
      # use system nano timestamp if not specified
      None -> ssp = 'ssp@' ++ console.now()
      # the sync point identifier needs to be a string
      ssp = ( '' ++ ssp )
    }
    # issue a system sync point
    dsyncSig = sink
    this.persistOutlet <- dsyncSig: ssp
    # the sig sink will be marked eos after sync done, wait for that
    for _ from dsyncSig do error( 'impossible' )
    return nil
  }

}

export class SuperBack {

  method __init__ (
    db as this.db, eid as this.eid,
  ) pass

  # informed reverse references, to referencers of `that` business object,
  # keyed by a pair of <rel-class>:<ref-attr>, then by the key attrs.
  _kins = {}

  # create an index for sorted kins, that automatically maintained by the data
  # back.
  #
  # a kin to a business object - the referee - (being either an entity or a
  # relationship), is another relationship object - the referer - which (through
  # a specific attribute) referencing the referee.
  #
  # DataBack automatically maintains a reverse reference from the referee to
  # the referer within an BoIndex object created by `createKinIndex()` or
  # BoSet object created by `createKinSet()`, resides in the referee's SuperBack
  # super object, available as a super attribute there from the referee object.
  method createKinIndex (
    kinAttr, relClass, relAttr, indexSpec, unique=false,
  ) {
    idx = if unique
    then BuIndex( indexSpec )
    else BoIndex( indexSpec )
    # chain the 2 assignments into single transaction
    this._kins[ relClass : ( '' ++ relAttr ) ] = (
      # will be available from `that` as super attr
      this@kinAttr = idx
    )
    return nil
  }

  # create a set for unordered kins, that automatically maintained by the data
  # back.
  #
  # a kin to a business object - the referee - (being either an entity or a
  # relationship), is another relationship object - the referer - which (through
  # a specific attribute) referencing the referee.
  #
  # DataBack automatically maintains a reverse reference from the referee to
  # the referer within an BoIndex object created by `createKinIndex()` or
  # BoSet object created by `createKinSet()`, resides in the referee's SuperBack
  # super object, available as a super attribute there from the referee object.
  method createKinSet ( kinAttr, relClass, relAttr ) {
    ks = BoSet()
    # chain the 2 assignments into single transaction
    this._kins[ relClass : ( '' ++ relAttr ) ] = (
      # will be available from `that` as super attr
      this@kinAttr = ks
    )
    return nil
  }

  # `extends db.superBack()` from a business object's __init__() triggers
  # this magic method, such a statement carries *persistent object creation*
  # semantic regarding the target `db` being the persistence backer.
  method (<-^) ( boScope ) {
    this?_boScope &> error (
      'bug: more than 1 business objects per SuperBack instance'
    )
    this._boScope = boScope

    case that?__db_init__ of { _ } -> that.__db_init__()

    # settle new object
    this.db._settle_obj( that, this )
  }

  # ( <-@) handles `this.xxx = yyy` from a business child (referred to by `that`)
  # (*<-@) handles `obj.xxx = yyy` for `obj` being a business child (referred to by `that`)

  method (*<-@) ( attrKey, attrVal ) {
    # treat all symbolic attrs as transient
    type( attrKey ) != StringType -> that@attrKey = attrVal

    case that?@attrKey of { attrValOld } -> {
      if attrValOld is attrVal then {
        return attrVal # no value change, nop
      }

      # cleanup the old relationship
      case attrValOld of { { SuperBack: sbRefOld } } -> this.db._cleanup_rel(
        that, this, attrKey, attrValOld, sbRefOld
      )
    }

    # apply the attribute update
    that@attrKey = attrVal

    # settle new attribute
    this.db._settle_attr( that, this, attrKey, attrVal )

    attrVal # keep the assignment result eval to target value as in normal cases
  }

  # use same method impl. for (<-@) and (*<-@), treating internal/external attr
  # updates the same
  this.(<-@) = (*<-@)

  # delete this business object in persistence respect
  method delete() this.db._cleanout_obj( that, this )

}
